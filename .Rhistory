# Evaluate the model on the test data (e.g., calculate RMSE, MSE, MAE)
rmse_value = sqrt(mean((predictions - y_test)^2))
mse_value = mean((predictions - y_test)^2)
mae_value = mean(abs(predictions - y_test))
# Print the evaluation metrics
cat("Testing Mean Squared Error (MSE):", mse_value, "\n")
cat("Testing Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Testing Mean Absolute Error (MAE):", mae_value, "\n")
#This one is LASSO
#Getting train and test splits
y_train = data_train$price
y_test = data_test$price
X_train = model.matrix(price ~ ., data = data_train)[, -8]#8th column is price
X_test = model.matrix(price ~ ., data = data_test)[, -8]
# Perform Lasso regression with cross-validation to select the lambda parameter
cv.lasso = cv.glmnet(X_train, y_train, alpha = 1)
# Fit the final Lasso model with the selected lambda using the training data
lasso_model = glmnet(X_train, y_train, alpha = 1, lambda = cv.lasso$lambda.min)
# Predict on the test data
predictions = predict(lasso_model, s = cv.lasso$lambda.min, newx = X_test)
# Evaluate the model on the test data (e.g., calculate RMSE, MSE, MAE)
rmse_value = sqrt(mean((predictions - y_test)^2))
mse_value = mean((predictions - y_test)^2)
mae_value = mean(abs(predictions - y_test))
# Print the evaluation metrics
cat("Testing Mean Squared Error (MSE):", mse_value, "\n")
cat("Testing Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Testing Mean Absolute Error (MAE):", mae_value, "\n")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(glmnet)
library(caret)
library(Metrics)
library(DescTools)
listings = read.csv("https://raw.githubusercontent.com/ethan2411/Data-601-602/main/listings.csv")
head(listings)
colnames(listings)
# Converting price to be numeric, removing $ and , to make it possible
listings = listings %>%
mutate(price = as.numeric(gsub("[$,]", "", price)))
# Check the first few rows of the updated dataframe
head(listings)
ggplot(data = listings, aes(x=price, y = neighbourhood_cleansed)) + geom_violin(col="blue")+ geom_boxplot(col="purple")+labs(title = "Distribution of Price by Neighbourhood", x = "Price", y = "Neighbourhood")
# Filter out the outliers so it is easier to see the graphs
listings_filtered = listings %>%
filter(price < 1500)
# Create the plot using the filtered data
ggplot(data = listings_filtered, aes(x = price, y = neighbourhood_cleansed)) + geom_boxplot(col = "purple") +labs(title = "Distribution of Price by Neighbourhood", x = "Price", y = "Neighbourhood")
# Create the plot using the filtered data
ggplot(data = listings_filtered, aes(x = price, y = neighbourhood_cleansed)) +
geom_violin(col = "purple") +labs(title = "Distribution of Price by Neighbourhood", x = "Price ($AUD)", y = "Neighbourhood")
# Create the plot using the filtered data
ggplot(data = listings_filtered, aes(x = price, y = room_type)) +
geom_violin(col = "blue", width= 1.5)+
geom_boxplot(col = "purple", width=0.2) +
theme_minimal() +
labs(
title = "Distribution of Price by Property Type",
x = "Price",
y = "Property Type"
)
ggplot(data = listings_filtered, aes(x = price, y = room_type)) + geom_violin(col = "blue", width= 1.5)+ geom_boxplot(col = "purple", width=0.2) + labs(title = "Distribution of Price by Room Type", x = "Price ($AUD)", y = "Room Type")
ggplot(data = listings, aes(y=neighbourhood_cleansed, fill=room_type)) + ylab("Neighbourhood") + geom_bar(color="black", width = 0.8) + scale_fill_manual(values=c("plum", "purple", "blue", "navy")) + ggtitle("Distribution of Room Types per Neighbourhood") + theme_minimal()
#creating the confidence intervals and getting mean price for each neighbourhood
neighbourhood_means = listings %>%
group_by(neighbourhood_cleansed) %>%
summarize(
mean_price = mean(price, na.rm = TRUE),
lower_ci = t.test(price, conf.level = 0.95)$conf.int[1],
upper_ci = t.test(price, conf.level = 0.95)$conf.int[2]
)
head(neighbourhood_means)
ggplot(neighbourhood_means, aes(x = reorder(neighbourhood_cleansed, mean_price), y = mean_price)) +
geom_bar(stat = "identity", col = 'red', fill = 'blue', width = 0.7) +labs(title = "Neighborhood Mean Prices", x = "Neighbourhood", y = "Mean Price ($AUD)") + coord_flip()
#plotting the confidence intervals
ggplot(neighbourhood_means, aes(x = reorder(neighbourhood_cleansed, mean_price), y = mean_price)) + geom_point() + geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.2) + coord_flip() + labs(x = "Neighbourhood", y = "Mean Price ($AUD)", title = "Mean Price by Neighborhood with Confidence Intervals")
#creating the confidence intervals and getting mean price for each neighbourhood
room_type_means = listings %>%
group_by(room_type) %>%
summarize(
mean_price = mean(price, na.rm = TRUE),
lower_ci = t.test(price, conf.level = 0.95)$conf.int[1],
upper_ci = t.test(price, conf.level = 0.95)$conf.int[2]
)
head(room_type_means)
ggplot(room_type_means, aes(x = reorder(room_type, mean_price), y = mean_price)) +
geom_bar(stat = "identity", col = 'red', fill = 'blue', width = 0.7) +labs(title = "Room Type Mean Prices", x = "Room Type", y = "Mean Price ($AUD)") + coord_flip()
#plotting the confidence intervals
ggplot(room_type_means, aes(x = reorder(room_type, mean_price), y = mean_price)) + geom_point() + geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.2) + coord_flip() + labs(x = "Room Type", y = "Mean Price ($AUD)", title = "Mean Price by Room Type with Confidence Intervals")
room_type_means
#P-value is tiny. This means we reject H_0 and conclude that there is a difference in mean prices throughout the neighbourhoods
options(Scipen = 999)
neighbourhood.aov = aov(price~neighbourhood_cleansed, data = listings)
summary(neighbourhood.aov)
#This we may or may not use. its the confidence intervals for every single comparison. We can probably remove the output and just go through it and see if there are any neighbourhoods that are significantly different than all others
PostHocTest(neighbourhood.aov, method="lsd")
plot(neighbourhood.aov, which = c(2,3))
#P-value shows there is a significant difference in mean price by room type
rooms.aov = aov(price~room_type, data = listings)
summary(rooms.aov)
#This shows exactly which rooms are different in price and which are not
PostHocTest(rooms.aov, method="lsd")
plot(rooms.aov, which = c(2,3))
# Seeing what columns have too many missing values, we will remove these
missing_values = is.na(listings)
missing_counts = colSums(missing_values)
columns5000_missing = missing_counts[missing_counts >5000]
print(columns5000_missing)
#create a feature for if a host has an about section? remove host_about
#other features too probably
#maybe how long someone has been a host will affect price?
listings$host_since = as.Date(listings$host_since)
listings$hostfor = as.numeric(difftime(Sys.Date(), listings$host_since, units = "days"))
sum(is.na(listings$hostfor))
# fill missing values in 'hostfor' with the mean
mean_hostfor = mean(listings$hostfor, na.rm = TRUE)
listings$hostfor[is.na(listings$hostfor)] = mean_hostfor
sum(is.na(listings$hostfor))
# fill missing 'beds' values with the median
# median is 2 and mean is 2.1 something
median_beds = median(listings$beds, na.rm = TRUE)
listings$beds[is.na(listings$beds)] = median_beds
#maybe if the host includes an in depth summary about themselves it will affect price?
listings$host_about_word_count = sapply(listings$host_about, function(text) {
words = unlist(strsplit(text, " "))
return(length(words))
})
#same for a description of the place?
# Extract the number of bathrooms available
# Need to find out how to also carry over decimal and "half-bath" listings
#if we can't do it maybe we just leave it as bathrooms_text
listings$bathrooms_count = as.numeric(gsub("[^0-9]", "", listings$bathrooms_text))
#Will need to remove this once the top part is figured out
listings$bathrooms_count <- ifelse(is.na(listings$bathrooms_count), 0, listings$bathrooms_count)
print(unique(listings$bathrooms_count))
print(unique(listings$bathrooms_text))
# Replace empty values with "f" so there isnt empty values
listings = listings %>%
mutate(host_is_superhost = ifelse(host_is_superhost == "", "f", host_is_superhost), host_has_profile_pic = ifelse(host_has_profile_pic == "", "f", host_has_profile_pic), host_identity_verified = ifelse(host_identity_verified == "", "f", host_identity_verified)
)
#removing columns that will definitely have nothing to do with price
listings = listings[, !(colnames(listings) %in% c("listing_url", "scrape_id", "last_scraped", "source", "picture_url", "host_id", "host_url", "host_thumbnail_url", "host_picture_url", "neighbourhood", "neighbourhood_group_cleansed", "license", "calendar_last_scraped", "calendar_updated", "property_type", "bedrooms", "host_since", "host_location", "host_about", "bathrooms_test", "bathrooms", "review_scores_communication", "review_scores_location", "review_scores_value", "reviews_per_month", "review_scores_rating", "review_scores_accuracy", "review_scores_cleanliness", "review_scores_checkin", "host_listings_count", "host_total_listings_count", "last_review", "host_name", "calculated_host_listings_count", "calculated_host_listings_count_entire_homes", "calculated_host_listings_count_private_rooms", "calculated_host_listings_count_shared_rooms", "host_neighbourhood", "availability_30", "availability_60", "availability_90", "minimum_minimum_nights", "maximum_minimum_nights", "minimum_maximum_nights", "maximum_maximum_nights", "host_verifications", "number_of_reviews_ltm", "number_of_reviews_l30d", "host_response_time", "host_response_rate", "host_acceptance_rate", "maximum_nights", "minimum_nights", "bathrooms_text", "has_availability", "first_review"))]
#bathrooms was removed at end because only bathroom_text will be needed, will probably have to do some feature engineering for lots of these variables
listings = listings[, !(colnames(listings) %in% c("description", "neighborhood_overview", "latitude", "longitude", "name", "amenities", "id"))]
head(listings)
colnames(listings)
#head(listings$beds)
sapply(listings, function(x) length(unique(x)))
#head(listings$calculated_host_listings_count_entire_homes)
print(unique(listings$bathrooms_count))
head(listings,10)
#price is our y variable
#For x-variables we have 15 total, there are 9 numerical and 6 categorical
print(unique(listings$host_has_profile_pic))
# Split the data into training and testing sets
#set.seed(12)  # For reproducibility
options(scipen = 999) # For Readability
#set.seed(2023)
trainIndex = createDataPartition(listings$price, p = .8,
list = FALSE,
times = 1)
data_train = listings[ trainIndex,]
data_test  = listings[-trainIndex,]
# Fit a linear regression model
linearmodel = lm(price ~ ., data = data_train)
summary.linearmodel = summary(linearmodel)
# Make predictions on the test data
predictions = predict(linearmodel, newdata = data_test)
rmse_value1 = rmse(predictions, data_train$price)
mse_value1 = mse(predictions, data_train$price)
mae_value1 = mae(predictions, data_train$price)
rmse_value = rmse(predictions, data_test$price)
mse_value = mse(predictions, data_test$price)
mae_value = mae(predictions, data_test$price)
# Print the evaluation metrics
#The N/A's are because there are null values in bathrooms_count
cat("Testing Mean Squared Error (MSE):", mse_value1, "\n")
cat("Testing Root Mean Squared Error (RMSE):", rmse_value1, "\n")
cat("Testing Mean Absolute Error (MAE):", mae_value1, "\n")
cat("Training Mean Squared Error (MSE):", mse_value, "\n")
cat("Training Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Training Mean Absolute Error (MAE):", mae_value, "\n")
library(broom) #converting the summary of the linear model to a dataframe.
linearmodel.df = tidy(sum.linearmodel)
linearmodel.df
significant.linearmodel.df = filter(linearmodel.df, p.value < 0.05)
head(significant.linearmodel.df,22)
#plots look alright, big upper tail on normaility plot but rest of it is fine i think
plot(linearmodel)
#Using stepwise selection to find the most important variables
data_train = na.omit(data_train)
model_stepwise = step(linearmodel, direction = "both")
#Checking the model
summary(model_stepwise)
df.stepwise = tidy(summary(model_stepwise))
df.stepwise
df.stepwise.significant = filter(df.stepwise, p.value < 0.05)
df.stepwise.significant
plot(model_stepwise)
#This one is LASSO
#Getting train and test splits
y_train = data_train$price
y_test = data_test$price
X_train = model.matrix(price ~ ., data = data_train)[, -8]#8th column is price
X_test = model.matrix(price ~ ., data = data_test)[, -8]
# Perform Lasso regression with cross-validation to select the lambda parameter
cv.lasso = cv.glmnet(X_train, y_train, alpha = 1)
# Fit the final Lasso model with the selected lambda using the training data
lasso_model = glmnet(X_train, y_train, alpha = 1, lambda = cv.lasso$lambda.min)
# Predict on the test data
predictions = predict(lasso_model, s = cv.lasso$lambda.min, newx = X_test)
# Evaluate the model on the test data (e.g., calculate RMSE, MSE, MAE)
rmse_value = sqrt(mean((predictions - y_test)^2))
mse_value = mean((predictions - y_test)^2)
mae_value = mean(abs(predictions - y_test))
# Print the evaluation metrics
cat("Testing Mean Squared Error (MSE):", mse_value, "\n")
cat("Testing Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Testing Mean Absolute Error (MAE):", mae_value, "\n")
coefficients(lasso_model)
# Perform Ridge regression with cross-validation to select the lambda parameter
cv.ridge = cv.glmnet(X_train, y_train, alpha = 0)
# Fit the final Ridge model with the selected lambda using the training data
ridge_model = glmnet(X_train, y_train, alpha = 0, lambda = cv.ridge$lambda.min)
# Predict on the test data
predictions = predict(ridge_model, s = cv.ridge$lambda.min, newx = X_test)
# Evaluate the model on the test data (e.g., calculate RMSE, MSE, MAE)
rmse_value = sqrt(mean((predictions - y_test)^2))
mse_value = mean((predictions - y_test)^2)
mae_value = mean(abs(predictions - y_test))
# Print the evaluation metrics
cat("Testing Mean Squared Error (MSE):", mse_value, "\n")
cat("Testing Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Testing Mean Absolute Error (MAE):", mae_value, "\n")
coefficients(ridge_model)
# Perform Elastic Net regression with cross-validation to select the lambda parameter
cv.en = cv.glmnet(X_train, y_train, alpha = 0.5)
# Fit the final Elastic Net model with the selected lambda using the training data
en_model = glmnet(X_train, y_train, alpha = 0.5, lambda = cv.en$lambda.min)
# Predict on the test data
predictions = predict(en_model, s = cv.en$lambda.min, newx = X_test)
# Evaluate the model on the test data (e.g., calculate RMSE, MSE, MAE)
rmse_value = sqrt(mean((predictions - y_test)^2))
mse_value = mean((predictions - y_test)^2)
mae_value = mean(abs(predictions - y_test))
# Print the evaluation metrics
cat("Testing Mean Squared Error (MSE):", mse_value, "\n")
cat("Testing Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Testing Mean Absolute Error (MAE):", mae_value, "\n")
coefficients(en_model)
citation('ggplot2')
citation('dplyr')
citation('glmnet')
citation('caret')
citation('Metrics')
#removing columns that will definitely have nothing to do with price
listings = listings[, !(colnames(listings) %in% c("listing_url", "scrape_id", "last_scraped", "source", "picture_url", "host_id", "host_url", "host_thumbnail_url", "host_picture_url", "neighbourhood", "neighbourhood_group_cleansed", "license", "calendar_last_scraped", "calendar_updated", "property_type", "bedrooms", "host_since", "host_location", "host_about", "bathrooms_test", "bathrooms", "review_scores_communication", "review_scores_location", "review_scores_value", "reviews_per_month", "review_scores_rating", "review_scores_accuracy", "review_scores_cleanliness", "review_scores_checkin", "host_listings_count", "host_total_listings_count", "last_review", "host_name", "calculated_host_listings_count", "calculated_host_listings_count_entire_homes", "calculated_host_listings_count_private_rooms", "calculated_host_listings_count_shared_rooms", "host_neighbourhood", "availability_30", "availability_60", "availability_90", "minimum_minimum_nights", "maximum_minimum_nights", "minimum_maximum_nights", "maximum_maximum_nights", "host_verifications", "number_of_reviews_ltm", "number_of_reviews_l30d", "host_response_time", "host_response_rate", "host_acceptance_rate", "maximum_nights", "minimum_nights", "bathrooms_text", "has_availability", "first_review"))]
#bathrooms was removed at end because only bathroom_text will be needed, will probably have to do some feature engineering for lots of these variables
listings = listings[, !(colnames(listings) %in% c("description", "neighborhood_overview", "latitude", "longitude", "name", "amenities", "id"))]
head(listings)
colnames(listings)
#head(listings$beds)
#removing columns that will definitely have nothing to do with price
listings = listings[, !(colnames(listings) %in% c("listing_url", "scrape_id", "last_scraped", "source", "picture_url", "host_id", "host_url", "host_thumbnail_url", "host_picture_url", "neighbourhood", "neighbourhood_group_cleansed", "license", "calendar_last_scraped", "calendar_updated", "property_type", "bedrooms", "host_since", "host_location", "host_about", "bathrooms_test", "bathrooms", "review_scores_communication", "review_scores_location", "review_scores_value", "reviews_per_month", "review_scores_rating", "review_scores_accuracy", "review_scores_cleanliness", "review_scores_checkin", "host_listings_count", "host_total_listings_count", "last_review", "host_name", "calculated_host_listings_count", "calculated_host_listings_count_entire_homes", "calculated_host_listings_count_private_rooms", "calculated_host_listings_count_shared_rooms", "host_neighbourhood", "availability_30", "availability_60", "availability_90", "minimum_minimum_nights", "maximum_minimum_nights", "minimum_maximum_nights", "maximum_maximum_nights", "host_verifications", "number_of_reviews_ltm", "number_of_reviews_l30d", "host_response_time", "host_response_rate", "host_acceptance_rate", "maximum_nights", "minimum_nights", "bathrooms_text", "has_availability", "first_review"))]
#bathrooms was removed at end because only bathroom_text will be needed, will probably have to do some feature engineering for lots of these variables
listings = listings[, !(colnames(listings) %in% c("description", "neighborhood_overview", "latitude", "longitude", "name", "amenities", "id"))]
head(listings)
colnames(listings)
#head(listings$beds)
sapply(listings, function(x) length(unique(x)))
#head(listings$calculated_host_listings_count_entire_homes)
print(unique(listings$bathrooms_count))
head(listings,10)
#price is our y variable
#For x-variables we have 15 total, there are 9 numerical and 6 categorical
print(unique(listings$host_has_profile_pic))
# Split the data into training and testing sets
options(scipen = 999) # For Readability
trainIndex = createDataPartition(listings$price, p = .8,
list = FALSE,
times = 1)
data_train = listings[ trainIndex,]
data_test  = listings[-trainIndex,]
# Fit a linear regression model
set.seed(123)
linearmodel = lm(price ~ ., data = data_train)
summary.linearmodel = summary(linearmodel)
summary.linearmodel
# Make predictions on the test data
predictions = predict(linearmodel, newdata = data_test)
rmse_value1 = rmse(predictions, data_train$price)
mse_value1 = mse(predictions, data_train$price)
mae_value1 = mae(predictions, data_train$price)
rmse_value = rmse(predictions, data_test$price)
mse_value = mse(predictions, data_test$price)
mae_value = mae(predictions, data_test$price)
# Print the evaluation metrics
#The N/A's are because there are null values in bathrooms_count
cat("Training Mean Squared Error (MSE):", mse_value, "\n")
cat("Training Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Training Mean Absolute Error (MAE):", mae_value, "\n")
library(broom) #converting the summary of the linear model to a dataframe.
linearmodel.df = tidy(summary.linearmodel)
linearmodel.df
significant.linearmodel.df = filter(linearmodel.df, p.value < 0.05)
head(significant.linearmodel.df,22)
print(listings[4,])
linear.predict = predict(linearmodel, data.frame(listings[4,]), interval = 'predict')
linear.predict
#plots look alright, big upper tail on normaility plot but rest of it is fine i think
plot(linearmodel)
#Using stepwise selection to find the most important variables
data_train = na.omit(data_train)
model_stepwise = step(linearmodel, direction = "both")
predictions_step = predict(model_stepwise, newdata = data_test)
rmse_value = rmse(predictions_step, data_test$price)
mse_value = mse(predictions_step, data_test$price)
mae_value = mae(predictions_step, data_test$price)
# Print the evaluation metrics
#The N/A's are because there are null values in bathrooms_count
#Checking the model
summary(model_stepwise)
cat("Training Mean Squared Error (MSE):", mse_value, "\n")
cat("Training Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Training Mean Absolute Error (MAE):", mae_value, "\n")
df.stepwise = tidy(summary(model_stepwise))
df.stepwise
df.stepwise.significant = filter(df.stepwise, p.value < 0.05)
df.stepwise.significant
stepwise.predict = predict(model_stepwise, data.frame(listings[4,]), interval = "predict")
stepwise.predict
plot(model_stepwise)
#This one is LASSO
#Getting train and test splits
y_train = data_train$price
y_test = data_test$price
X_train = model.matrix(price ~ ., data = data_train)[, -8]#8th column is price
X_test = model.matrix(price ~ ., data = data_test)[, -8]
# Perform Lasso regression with cross-validation to select the lambda parameter
cv.lasso = cv.glmnet(X_train, y_train, alpha = 1)
# Fit the final Lasso model with the selected lambda using the training data
lasso_model = glmnet(X_train, y_train, alpha = 1, lambda = cv.lasso$lambda.min)
# Predict on the test data
predictions = predict(lasso_model, s = cv.lasso$lambda.min, newx = X_test)
# Evaluate the model on the test data (e.g., calculate RMSE, MSE, MAE)
rmse_value = sqrt(mean((predictions - y_test)^2))
mse_value = mean((predictions - y_test)^2)
mae_value = mean(abs(predictions - y_test))
# Print the evaluation metrics
cat("Testing Mean Squared Error (MSE):", mse_value, "\n")
cat("Testing Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Testing Mean Absolute Error (MAE):", mae_value, "\n")
coefficients(lasso_model)
# for LASSO
# Calculate residuals
residuals = y_test-predictions
# Normality of Residuals
# Q-Q Plot
qqnorm(residuals)
qqline(residuals)
# Homoscedasticity of Residuals
# Scatterplot of Residuals vs. Fitted Values
plot(predictions, residuals, main = "Residuals vs. Fitted Values", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "red")
# Perform Ridge regression with cross-validation to select the lambda parameter
cv.ridge = cv.glmnet(X_train, y_train, alpha = 0)
# Fit the final Ridge model with the selected lambda using the training data
ridge_model = glmnet(X_train, y_train, alpha = 0, lambda = cv.ridge$lambda.min)
# Predict on the test data
predictions = predict(ridge_model, s = cv.ridge$lambda.min, newx = X_test)
# Evaluate the model on the test data (e.g., calculate RMSE, MSE, MAE)
rmse_value = sqrt(mean((predictions - y_test)^2))
mse_value = mean((predictions - y_test)^2)
mae_value = mean(abs(predictions - y_test))
# Print the evaluation metrics
cat("Testing Mean Squared Error (MSE):", mse_value, "\n")
cat("Testing Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Testing Mean Absolute Error (MAE):", mae_value, "\n")
coefficients(ridge_model)
# for Ridge
# Calculate residuals
residuals = y_test-predictions
# Normality of Residuals
# Q-Q Plot
qqnorm(residuals)
qqline(residuals)
# Homoscedasticity of Residuals
# Scatterplot of Residuals vs. Fitted Values
plot(predictions, residuals, main = "Residuals vs. Fitted Values", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "red")
# Perform Elastic Net regression with cross-validation to select the lambda parameter
cv.en = cv.glmnet(X_train, y_train, alpha = 0.5)
# Fit the final Elastic Net model with the selected lambda using the training data
en_model = glmnet(X_train, y_train, alpha = 0.5, lambda = cv.en$lambda.min)
# Predict on the test data
predictions = predict(en_model, s = cv.en$lambda.min, newx = X_test)
# Evaluate the model on the test data (e.g., calculate RMSE, MSE, MAE)
rmse_value = sqrt(mean((predictions - y_test)^2))
mse_value = mean((predictions - y_test)^2)
mae_value = mean(abs(predictions - y_test))
# Print the evaluation metrics
cat("Testing Mean Squared Error (MSE):", mse_value, "\n")
cat("Testing Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Testing Mean Absolute Error (MAE):", mae_value, "\n")
coefficients(en_model)
# for Elastic Net
# Calculate residuals
residuals = y_test-predictions
# Normality of Residuals
# Q-Q Plot
qqnorm(residuals)
qqline(residuals)
# Homoscedasticity of Residuals
# Scatterplot of Residuals vs. Fitted Values
plot(predictions, residuals, main = "Residuals vs. Fitted Values", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "red")
citation('ggplot2')
citation('dplyr')
citation('glmnet')
citation('caret')
citation('Metrics')
# for Elastic Net
# Calculate residuals
residuals = y_test-predictions
# Normality of Residuals
# Q-Q Plot
qqnorm(residuals)
qqline(residuals)
# Homoscedasticity of Residuals
# Scatterplot of Residuals vs. Fitted Values
plot(predictions, residuals, main = "Residuals vs. Fitted Values", xlab = "Fitted Values", ylab = "Residuals", col ="royal blue")
abline(h = 0, col = "red")
# for Elastic Net
# Calculate residuals
residuals = y_test-predictions
# Normality of Residuals
# Q-Q Plot
qqnorm(residuals)
qqline(residuals)
# Homoscedasticity of Residuals
# Scatterplot of Residuals vs. Fitted Values
plot(predictions, col ="royal blue", residuals, main = "Residuals vs. Fitted Values", xlab = "Fitted Values", ylab = "Residuals", col ="royal blue")
# for Elastic Net
# Calculate residuals
residuals = y_test-predictions
# Normality of Residuals
# Q-Q Plot
qqnorm(residuals)
qqline(residuals)
# Homoscedasticity of Residuals
# Scatterplot of Residuals vs. Fitted Values
plot(predictions, residuals, main = "Residuals vs. Fitted Values", xlab = "Fitted Values", ylab = "Residuals", col ="royal blue")
abline(h = 0, col = "red")
# for Elastic Net
# Calculate residuals
residuals = y_test-predictions
# Normality of Residuals
# Q-Q Plot
qqnorm(residuals)
qqline(residuals)
# Homoscedasticity of Residuals
# Scatterplot of Residuals vs. Fitted Values
plot(predictions, residuals, col ="royal blue", main = "Residuals vs. Fitted Values", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "red")
# for Elastic Net
# Calculate residuals
residuals = y_test-predictions
# Normality of Residuals
# Q-Q Plot
qqnorm(residuals)
qqline(residuals)
# Homoscedasticity of Residuals
# Scatterplot of Residuals vs. Fitted Values
plot(predictions, col = "royal blue")
plot(residuals, col ="royal blue", main = "Residuals vs. Fitted Values", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "red")
# for Elastic Net
# Calculate residuals
residuals = y_test-predictions
# Normality of Residuals
# Q-Q Plot
qqnorm(residuals)
qqline(residuals)
# Homoscedasticity of Residuals
# Scatterplot of Residuals vs. Fitted Values
plot(predictions, col = "royal blue", fill 'royal blue)
plot(residuals, col ="royal blue", main = "Residuals vs. Fitted Values", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "red")
# for Elastic Net
# Calculate residuals
residuals = y_test-predictions
# Normality of Residuals
# Q-Q Plot
qqnorm(residuals)
qqline(residuals)
# Homoscedasticity of Residuals
# Scatterplot of Residuals vs. Fitted Values
plot(predictions, col = "royal blue")
plot(residuals, col ="royal blue", main = "Residuals vs. Fitted Values", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "red")
# for Elastic Net
# Calculate residuals
residuals = y_test-predictions
# Normality of Residuals
# Q-Q Plot
qqnorm(residuals)
qqline(residuals)
# Homoscedasticity of Residuals
# Scatterplot of Residuals vs. Fitted Values
plot(predictions, residuals, col ="royal blue", main = "Residuals vs. Fitted Values", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "red")
